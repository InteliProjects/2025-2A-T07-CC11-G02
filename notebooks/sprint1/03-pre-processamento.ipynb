{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5_ngGCH0Tl2"
      },
      "outputs": [],
      "source": [
        "!pip -q install nltk pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zxqRMPJeaJh",
        "outputId": "c43f937c-6e5c-447d-fd5a-7d5dfac565ae"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "from google.colab import drive\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "nltk.download(\"rslp\", quiet=True)\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkJTPVr_0iem"
      },
      "outputs": [],
      "source": [
        "CSV_PATH = \"/content/drive/MyDrive/M11/dados/all_msgs_whatsapp_instagram.csv\"\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df = (\n",
        "    df[[\"message\"]]\n",
        "    .dropna()\n",
        "    .rename(columns={\"message\": \"original\"})\n",
        "    .reset_index(drop=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2iDA1Ye2TeV"
      },
      "outputs": [],
      "source": [
        "def to_lower(text: str) -> str:\n",
        "    return text.lower()\n",
        "\n",
        "\n",
        "def strip_accents(text: str) -> str:\n",
        "    normalized = unicodedata.normalize(\"NFD\", text)\n",
        "    return \"\".join(ch for ch in normalized if unicodedata.category(ch) != \"Mn\")\n",
        "\n",
        "\n",
        "PUNCT_PATTERN = re.compile(r\"[\\\"'`.,;:!?()\\[\\]{}<>@#$%^&*_+=~/\\\\|-]\")\n",
        "\n",
        "\n",
        "def remove_punctuation(text: str) -> str:\n",
        "    return PUNCT_PATTERN.sub(\" \", text)\n",
        "\n",
        "\n",
        "def simple_tokenize(text: str) -> List[str]:\n",
        "    return [t for t in text.split() if t.strip()]\n",
        "\n",
        "\n",
        "pt_stopwords = set(stopwords.words(\"portuguese\"))\n",
        "\n",
        "\n",
        "def remove_stopwords(tokens: List[str]) -> List[str]:\n",
        "    return [t for t in tokens if t not in pt_stopwords]\n",
        "\n",
        "\n",
        "stemmer = RSLPStemmer()\n",
        "\n",
        "\n",
        "def stem_tokens(tokens: List[str]) -> List[str]:\n",
        "    return [stemmer.stem(t) for t in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "FPv2R0FD2WMC",
        "outputId": "35abee82-6d0e-4ad4-a14b-5da6f834a844"
      },
      "outputs": [],
      "source": [
        "df[\"lower\"] = df[\"original\"].apply(to_lower)\n",
        "df[\"no_accents\"] = df[\"lower\"].apply(strip_accents)\n",
        "df[\"no_punct\"] = df[\"no_accents\"].apply(remove_punctuation)\n",
        "df[\"tokens\"] = df[\"no_punct\"].apply(simple_tokenize)\n",
        "df[\"no_stopwords\"] = df[\"tokens\"].apply(remove_stopwords)\n",
        "df[\"stems\"] = df[\"no_stopwords\"].apply(stem_tokens)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "1uywWsZq2Ygi",
        "outputId": "a552cc7a-7c73-490a-ad57-6b87de5b2149"
      },
      "outputs": [],
      "source": [
        "PIPELINE_STEPS = {\n",
        "    \"lower\": True,\n",
        "    \"strip_accents\": True,\n",
        "    \"remove_punctuation\": True,\n",
        "    \"tokenize\": True,\n",
        "    \"remove_stopwords\": True,\n",
        "    \"stem\": True,\n",
        "}\n",
        "\n",
        "\n",
        "def run_pipeline(text: str):\n",
        "    x = text\n",
        "    steps_result = {\"original\": text}\n",
        "    if PIPELINE_STEPS[\"lower\"]:\n",
        "        x = to_lower(x)\n",
        "        steps_result[\"lower\"] = x\n",
        "    if PIPELINE_STEPS[\"strip_accents\"]:\n",
        "        x = strip_accents(x)\n",
        "        steps_result[\"no_accents\"] = x\n",
        "    if PIPELINE_STEPS[\"remove_punctuation\"]:\n",
        "        x = remove_punctuation(x)\n",
        "        steps_result[\"no_punct\"] = x\n",
        "    if PIPELINE_STEPS[\"tokenize\"]:\n",
        "        x = simple_tokenize(x)\n",
        "        steps_result[\"tokens\"] = deepcopy(x)\n",
        "    if PIPELINE_STEPS[\"remove_stopwords\"]:\n",
        "        x = remove_stopwords(x)\n",
        "        steps_result[\"no_stopwords\"] = deepcopy(x)\n",
        "    if PIPELINE_STEPS[\"stem\"]:\n",
        "        x = stem_tokens(x)\n",
        "        steps_result[\"stems\"] = deepcopy(x)\n",
        "    steps_result[\"final\"] = x\n",
        "    return steps_result\n",
        "\n",
        "\n",
        "pipeline_df = pd.DataFrame([run_pipeline(s) for s in df[\"original\"].tolist()])\n",
        "pipeline_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "2netXh1RcCgN",
        "outputId": "a6c8924f-7b21-4e51-9bc1-a0662f91fd85"
      },
      "outputs": [],
      "source": [
        "# Figura 1: diagrama do pipeline (gerado via networkx/matplotlib)\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "stages = [\n",
        "    \"original\",\n",
        "    \"lower\",\n",
        "    \"no_accents\",\n",
        "    \"no_punct\",\n",
        "    \"tokens\",\n",
        "    \"no_stopwords\",\n",
        "    \"stems\",\n",
        "]\n",
        "G = nx.DiGraph()\n",
        "for i in range(len(stages) - 1):\n",
        "    G.add_edge(stages[i], stages[i + 1])\n",
        "\n",
        "pos = {\n",
        "    \"original\": (0, 0),\n",
        "    \"lower\": (1.5, 0),\n",
        "    \"no_accents\": (3.0, 0),\n",
        "    \"no_punct\": (4.5, 0),\n",
        "    \"tokens\": (6.0, 0),\n",
        "    \"no_stopwords\": (7.5, 0),\n",
        "    \"stems\": (9.0, 0),\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(12, 3.8))\n",
        "nx.draw(\n",
        "    G,\n",
        "    pos,\n",
        "    with_labels=True,\n",
        "    node_color=\"#e6f2ff\",\n",
        "    node_size=8000,\n",
        "    arrows=True,\n",
        "    arrowstyle=\"->\",\n",
        "    arrowsize=15,\n",
        ")\n",
        "plt.title(\"Figura 1 - Pipeline de pré-processamento textual\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "print(\n",
        "    \"Legenda - Figura 1: Fluxo de estágios do pipeline do texto bruto (original) até a saída final (stems).\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "oKPm_WEqcCgQ",
        "outputId": "41e92fe2-f86f-4cb4-e4bc-77f94b47b164"
      },
      "outputs": [],
      "source": [
        "# Tabela 1: resumo de tamanho das mensagens (tokens)\n",
        "import pandas as pd\n",
        "\n",
        "lengths = pd.Series([len(t) for t in df[\"tokens\"]])\n",
        "lengths_summary = lengths.describe()\n",
        "lengths_summary.to_frame(name=\"tokens_por_mensagem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "YnvWYGHecCgS",
        "outputId": "e3503305-8b99-4e13-a62b-5f25c6c8a24c"
      },
      "outputs": [],
      "source": [
        "# Gráfico 1: histograma de tamanho das mensagens (tokens)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.hist(lengths, bins=30, color=\"#4e79a7\", edgecolor=\"white\")\n",
        "plt.title(\"Gráfico 1 - Distribuição do tamanho das mensagens (número de tokens)\")\n",
        "plt.xlabel(\"nº de tokens por mensagem\")\n",
        "plt.ylabel(\"frequência\")\n",
        "plt.show()\n",
        "print(\n",
        "    \"Legenda - Gráfico 1: Histograma do número de tokens por mensagem após tokenização simples.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "xjm5EBoEcCgT",
        "outputId": "ee98af34-c736-430f-f8bd-f7f2c87ae389"
      },
      "outputs": [],
      "source": [
        "# Tabela 2: palavras mais frequentes após stopwords + stem\n",
        "from collections import Counter\n",
        "\n",
        "stems_flat = [t for tokens in df[\"stems\"] for t in tokens]\n",
        "most_common = Counter(stems_flat).most_common(20)\n",
        "mc_df = pd.DataFrame(most_common, columns=[\"termo\", \"frequencia\"])\n",
        "mc_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IKmYX3ZKcCgV",
        "outputId": "092310e2-d5f0-4cca-ace4-438c8e30cad8"
      },
      "outputs": [],
      "source": [
        "# Gráfico 2: top-20 termos após stopwords + stem\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.bar(mc_df[\"termo\"], mc_df[\"frequencia\"], color=\"#f28e2b\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.title(\n",
        "    \"Gráfico 2 - Termos mais frequentes após remoção de stopwords e stemming (top-20)\"\n",
        ")\n",
        "plt.xlabel(\"termo\")\n",
        "plt.ylabel(\"frequência\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\n",
        "    \"Legenda - Gráfico 2: Frequência dos 20 termos mais comuns após o pipeline final.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "IY8k3N3QcCgy",
        "outputId": "419e0e23-e2f2-46d9-8bfd-362d219b19e8"
      },
      "outputs": [],
      "source": [
        "# Tabela 3: estatísticas por etapa do pipeline (comprimento médio)\n",
        "import numpy as np\n",
        "\n",
        "stats = []\n",
        "for col in [\"original\", \"lower\", \"no_accents\", \"no_punct\"]:\n",
        "    stats.append(\n",
        "        {\"etapa\": col, \"comprimento_medio\": df[col].astype(str).str.len().mean()}\n",
        "    )\n",
        "for col in [\"tokens\", \"no_stopwords\", \"stems\"]:\n",
        "    stats.append({\"etapa\": col, \"comprimento_medio\": df[col].apply(len).mean()})\n",
        "stats_df = pd.DataFrame(stats)\n",
        "stats_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ClMMHHXbcCgy",
        "outputId": "3b675389-c75e-4fab-a2ca-605e6c26c663"
      },
      "outputs": [],
      "source": [
        "# Gráfico 3: comprimento médio por etapa do pipeline\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(stats_df[\"etapa\"], stats_df[\"comprimento_medio\"], color=\"#59a14f\")\n",
        "plt.xticks(rotation=30, ha=\"right\")\n",
        "plt.title(\"Gráfico 3 - Comprimento médio por etapa do pipeline\")\n",
        "plt.xlabel(\"etapa\")\n",
        "plt.ylabel(\"comprimento médio\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Legenda - Gráfico 3: Comparação do comprimento médio entre etapas do pipeline.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
